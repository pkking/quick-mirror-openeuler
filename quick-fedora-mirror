#!/bin/zsh
# Simple script to grab the file list from Fedora and rsync everything that's
# changed since the last time we pulled.
#
# Originally written by Jason Tibbitts <tibbs@math.uh.edu> in 2016.
# Donated to the public domain.  If you require a statement of license, please
# consider this work to be licensed as "CC0 Universal", any version you choose.

# Variables in upper case are user configurables.

# ZSHISM? Turn on empty globs
set -G
export LANG=C
# ZSHISM? newline for IFS.
IFS=$'\n'

# Do this very early
starttime=$(date +%s)
# Paranoia; give us a few extra seconds.
starttime=$(($starttime-5))

# Debug output;
# Level 0: nothing except errors.
# Level 1: lvl0 unless there is a tranfer, and then basic info and times.
# Output goes to a file which may be spit out at the end of the run.
# Level >= 2: Always some info, output to the terminal.
db1 () {
    if (( VERBOSE >= 2 )); then
        echo $*
    elif (( VERBOSE >= 1 )); then
        echo $* >> $outfile
    fi
    # Otherwise output nothing....
}
db1f () { db1 $(printf $*); }

db2 () { (( VERBOSE >= 2 )) && echo $*}
db2f () { (( VERBOSE >= 2 )) && printf $*}
db3 () { (( VERBOSE >= 3 )) && echo '>>' $*}
db4 () { (( VERBOSE >= 4 )) && echo '>>>>' $*}
sep () { (( VERBOSE >= 2 )) && echo '============================================================'}

logwrite () {
    # Send logging info to the right place
    if [[ -n $LOGJOURNAL ]]; then
        echo $* >&3
    elif [[ -n $LOGFILE && -w $LOGFILE ]]; then
        echo $(date '+%b %d %T') $* >> $LOGFILE
    fi
}

logit () {
    # Basic logging function
    local item=$1
    shift
    if [[ $LOGITEMS =~ $item || $LOGITEMS =~ '@' ]]; then
       logwrite $*
   fi
   if (( VERBOSE >= 3 )); then
       db3 Log: $*
   fi
}

lock () {
    eval "exec 9>>$1"
    flock -n 9 && return 0
    return 1
}

finish () {
    # Finish up.  Dump the output file to stdout unless an argument is passed.
    db1 "========================="
    db1 "Mirror finished: $(date)"
    logit R "Run end."
    if [[ -z $1 ]]; then
        cat $outfile
    fi
    exit 0
}

# Client-side file list filtering.
filter () {
    if [[ -n $FILTEREXP ]]; then
        sed -i -r -e "\,$FILTEREXP,d" $1
    fi
}

# Produce human-readable byte counts
# Yes, this has a bug at 1024EB
hr_b () {
    typeset -F2 out

    if [[ $1 -lt 1024 ]]; then
        echo ${1}B
        return
    fi

    out=$(( $1 / 1024. ))
    for unit in KB MB GB TB PB EB; do
        (( $out < 1024 )) && break
        out=$(( out / 1024. ))
    done

    echo ${out}${unit}
}

# Produce human-readable second counts
hr_s () {
    typeset -F2 out=$1

    if [[ $1 -lt 60 ]]; then
        echo ${1}s
        return
    fi

    out=$(( $1 / 60. ))
    if [[ $out -lt 60 ]]; then
        echo ${out}m
        return
    fi

    out=$(( $out / 60. ))
    echo ${out}h
}

parse_rsync_stats () {
    # Parse some of the statistics that rsync gives us.
    # Takes an rsync output log (stdout) as an argument.
    # No return value, but sill set several global variables:
    #   rsfilestransferred
    #   rsfilesize
    #   rstotalbytesreceived
    #   rstotalbytessent
    #   rsfilelistgentime
    #   rsfilelisttransfertime
    #   rstransferspeed
    #   rsspeedup
    # These will all be set unset if not present in the given log.
    #
    # Here's the full block of info that rsync provides:
    #
    # Number of files: 11,140 (reg: 9,344, dir: 1,796)
    # Number of created files: 1,329 (reg: 1,327, dir: 2)
    # Number of deleted files: 0
    # Number of regular files transferred: 1,182
    # Total file size: 165,405,056,029 bytes
    # Total transferred file size: 3,615,178,247 bytes
    # Literal data: 3,229,943,512 bytes
    # Matched data: 385,234,735 bytes
    # File list size: 468,791
    # File list generation time: 0.217 seconds
    # File list transfer time: 0.000 seconds
    # Total bytes sent: 1,249,286
    # Total bytes received: 3,231,373,895
    #
    # sent 1,249,286 bytes  received 3,231,373,895 bytes  81,838,561.54 bytes/sec
    # total size is 165,405,056,029  speedup is 51.17

    local log=$1

    # Number of regular files transferred: 1
    unset rsfilestransferred
    rsfilestransferred=$(awk '/^Number of regular files transferred:/ {print $6; exit}' $log)

    # Total file size: 10,174,746 bytes
    unset rsfilesize
    rsfilesize=$(awk '/^Total file size: (.*) bytes/ {print $4; exit}' $log | sed -e 's/,//g')

    # Total bytes received: 2,425,728
    unset rstotalbytesreceived
    rstotalbytesreceived=$(awk '/^Total bytes received: (.*)/ {print $4; exit}' $log | sed -e 's/,//g')

    # Total bytes sent: 384,602
    unset rstotalbytessent
    rstotalbytessent=$(awk '/^Total bytes sent: (.*)/ {print $4; exit}' $log | sed -e 's/,//g')

    # File list generation time: 0.308 seconds
    unset rsfilelistgentime
    rsfilelistgentime=$(awk '/^File list generation time: (.*) seconds/ {print $5; exit}' $log)

    # File list transfer time: 0.000 seconds
    unset rsfilelisttransfertime
    rsfilelisttransfertime=$(awk '/^File list transfer time: (.*) seconds/ {print $5; exit}' $log)

    # sent 71 bytes  received 2,425,728 bytes  156,503.16 bytes/sec
    unset rstransferspeed
    rstransferspeed=$(awk '/^sent .* bytes .* received .* bytes (.*) bytes\/sec$/ {print $7; exit}' $log \
                      | sed -e 's/,//g')

    # total size is 10,174,746  speedup is 4.19
    unset rsspeedup
    rsspeedup=$(awk '/^total size is .* speedup is (.*)$/ {print $7; exit}' $log)
}

do_rsync () {
    # The main function to do a transfer
    # Accepts four options:
    #   1) The source repository
    #   2) The destination directory
    #   3) The list of files
    #   4) The name of an array containing additional rsync options
    #
    # This may sleep and retry when receiving an error.
    # Returns the last rsync return code; 0 if no error.
    #

    local src=$1 dest=$2 files=$3 opts=$4
    local runcount=0
    local log=$(mktemp -p . rsync-out-XXXXXX.log)
    local errlog=$(mktemp -p . rsync-err-XXXXXX.log)
    local sleep rr rvbash rvzsh

    local -a verboseopts

    # These add to the default rsync verbosity
    (( VERBOSE >= 7 )) && verboseopts+=(--progress)
    (( VERBOSE >= 5 )) && verboseopts+=(-v)
    (( VERBOSE >= 4 )) && verboseopts+=(-v)

    # Usually we won't want to see this.
    (( VERBOSE <= 3 )) && verboseopts+=(--no-motd)

    flopts=(--files-from=$files)

    while true; do
        runcount=$(( runcount+1 ))
        # ZSHISM:  (P) flag to act on a variable by name.  Sadly, bash has
        # broken array handling.   bash 4.3 has local -n for this.  Older bash
        # needs hacks, or eval.  More info:
        # https://stackoverflow.com/questions/1063347/passing-arrays-as-parameters-in-bash
        # Or just use a freaking global.

        # We have to do this separately because you can't redirect to /dev/stderr when running under sudo.
        db3 Calling $RSYNC $RSYNCOPTS $verboseopts $flopts ${(P)opts} $src $dest
        logit c calling $RSYNC $RSYNCOPTS $verboseopts $flopts ${(P)opts} $src $dest
        if (( VERBOSE >= 5 )); then
            $RSYNC $RSYNCOPTS $verboseopts $flopts ${(P)opts} $src $dest | tee $log
            rvbash="${PIPESTATUS[0]}" rvzsh="${pipestatus[1]}" rr=$rvbash$rvzsh
        elif (( VERBOSE >= 2 )); then
            $RSYNC $RSYNCOPTS $verboseopts $flopts ${(P)opts} $src $dest >> $log
            rvbash="${PIPESTATUS[0]}" rvzsh="${pipestatus[1]}" rr=$rvbash$rvzsh
        else
            $RSYNC $RSYNCOPTS $verboseopts $flopts ${(P)opts} $src $dest >> $log 2>> $errlog
            rvbash="${PIPESTATUS[0]}" rvzsh="${pipestatus[1]}" rr=$rvbash$rvzsh
        fi

        # We should ignore; 0 (obviously), 24
        # If we retried on 24 (missing files on server) we'd never make progress.
        # We should retry: 5 10 23 30 35
        if (( rr == 0 )); then
            break
        elif (( rr == 24 )); then
            logit e "rsync says source files vanished; ignoring"
            break
        elif (( rr == 5 || rr == 10 || rr == 23 || rr == 30 || rr == 35 )); then
            # First see if we've already tried too many times
            if (( runcount >= MAXRETRIES )); then
                logit E rsync from $REMOTE/$module failed
                (>&2 echo "Could not sync from $REMOTE/$module")
                [[ -f $errlog ]] && (>&2 cat $errlog)
                return $rr
            fi
            sleep=$(( 2 ** runcount ))
            logit e "rsync returned $rr (retryable), sleeping for $sleep"
            db2 rsync failed: sleeping for $sleep
            sleep $sleep
        else
            # Some other code we didn't anticipate
            logit E rsync returned $rr.  This is not recoverable.
            (>&2 echo rsync returned $rr; this is not recoverable.
                [[ -f $errlog ]] && cat $errlog
            )
            return $rr
        fi
    done

    logit C rsync call completed succesfully with return $rr

    parse_rsync_stats $log
    return $rr
}

parse_args () {
    # Process arguments, setting all sorts of globals
    while [[ $# > 0 ]]; do
        opt=$1
        case $opt in
            -a)
                alwayscheck=1
                ;;
            -c)
                cfgfile=$2
                shift
                if [[ ! -r $cfgfile ]]; then
                    (>&2 echo Cannot read $cfgfile)
                    exit 1
                fi
                ;;
            -d) # Debugging
                verboseopt=$2
                shift
                ;;
            -n)
                rsyncdryrun=1
                skipdelete=1
                skiptimestamp=1
                ;;
            -N)
                skipdelete=1
                skiptimestamp=1
                ;;
            -t)
                backdate=$2
                alwayscheck=1
                shift
                ;;
            -T)
                backdate=$(date -d "$2" +%s)
                alwayscheck=1
                shift
                ;;
            --dir-times)
                updatealldirtimes=1
                ;;
            *)
                (>&2 echo "Unrecognized argument.")
                exit 1
                ;;
        esac
        shift
    done


}

read_config () {
    # Load up the configuration file from any of a number of locations
    local file
    for file in \
        $cfgfile \
        /etc/quick-fedora-mirror.conf \
        ~/.config/quick-fedora-mirror.conf \
        $(dirname $0)/quick-fedora-mirror.conf \
        ./quick-fedora-mirror.conf; \
    do
        if [[ -r $file ]]; then
            source $file
            cfgfile=$file
            break
        fi
    done

    # Override some settings with previously parsed command-line options
    [[ -n $verboseopt ]] && VERBOSE=$verboseopt

    # Check that the required parameters were provided
    if [[ -z $DESTD ]]; then
        (>&2 echo "You must define DESTD in your configuration file ($cfgfile).")
    fi
    if [[ -z $TIMEFILE ]]; then
        (>&2 echo "You must define TIMEFILE in your configuration file ($cfgfile).")
    fi
}


# Main program execution
# ======================
parse_args "$@"

# Mapping from module names to directories under fedora-buffet
# ZSHISM (initialize associative array)
typeset -A MODULEMAPPING
typeset -A MIRRORMANAGERMAPPING
MODULEMAPPING=(
    fedora-alt          alt
    fedora-archive      archive
    fedora-enchilada    fedora
    fedora-epel         epel
    fedora-secondary    fedora-secondary
    )

MIRRORMANAGERMAPPING=(
    fedora-alt          'fedora other'
    fedora-archive      'fedora archive'
    fedora-enchilada    'fedora linux'
    fedora-epel         'fedora epel'
    fedora-secondary    'fedora secondary arches'
    )

# Default arguments; override in quick-fedora-mirror.conf
VERBOSE=0
LOGITEMS=aeElrR

DESTD=
TIMEFILE=

CHECKIN_HOST=$(hostname)
CURL=/usr/bin/curl
FILELIST='fullfiletimelist-$mdir'
FFILELIST='fullfilelist'
MIRRORMANAGER=https://admin.fedoraproject.org/mirrormanager/xmlrpc
REMOTE=rsync://dl.fedoraproject.org
RSYNC=/usr/bin/rsync
WARNDELAY=$((60 * 60 * 24))
MAXRETRIES=10

rsyncver=$(rsync --version | head -1 | awk '{print $3}')
if [[ $rsyncver == 3.1* ]]; then
    RSYNCOPTS=(-aSH -f 'R .~tmp~' --stats --preallocate --delay-updates --out-format='@ %i  %n%L')
else
    RSYNCOPTS=(-aSH -f 'R .~tmp~' --stats --delay-updates --out-format='@ %i  %n%L')
fi

MASTERMODULE=fedora-buffet
MODULES=(fedora-enchilada fedora-epel)

read_config

# Find the previous mirror time, and backdate if necessary
LASTTIME=0
if [[ -r $TIMEFILE ]]; then
    source $TIMEFILE
fi
if [[ -n $backdate ]]; then
    LASTTIME=$backdate
fi

# Make a temp dir and clean it up unless we're doing a lot of debugging
if [[ -z $TMPDIR ]]; then
    tempd=$(mktemp -d -t quick-mirror.XXXXXXXXXX)
else
    tempd=$(mktemp -d -p $TMPDIR -t quick-mirror.XXXXXXXXXX)
fi

if [[ $? -ne 0 ]]; then
    (>&2 echo "Creating temporary directory failed?")
    exit 1
fi
if (( VERBOSE <= 8 )); then
    trap "rm -rf $tempd" EXIT
fi

# Set up a FIFO for logging.  Just calling systemd-cat repeatedly just gives us
# a different PID every time, which is annoying.
if [[ -n $LOGJOURNAL ]]; then
    logfifo=$tempd/journal.fifo
    mkfifo $logfifo
    systemd-cat -t quick-fedora-mirror < $logfifo &
    exec 3>$logfifo
fi

outfile=$tempd/output
touch $outfile

cd $tempd

# At this point we can acquire the lock
lock $TIMEFILE
if (( ? != 0 )); then
    db4 Could not acquire lock.
    logit k lock contention
    # Maybe we haven't been able to mirror for some time....
    delay=$(( starttime - LASTTIME ))
    if [[ -n $backdate || $LASTTIME -eq 0 ]]; then
        delay=0
    fi

    if (( delay > WARNDELAY )); then
        (>&2 echo No completed run since $(date -d @$LASTTIME ).)
        logit E No completed run since $(date -d @$LASTTIME ).
    fi
    exit 1
fi

db1 "Mirror starting: $(date)"
logit r Run start: cfg $cfgfile, tmp $tempd

if (( VERBOSE >= 6 )); then
    echo Times:
    echo LASTTIME=$LASTTIME
    echo starttime=$starttime
    echo TIMEFILE=$TIMEFILE
    echo Dirs:
    echo tempd=$tempd
    echo DESTD=$DESTD
    echo Rsync:
    echo REMOTE=$REMOTE
    echo MASTERMODULE=$MASTERMODULE
    echo RSYNC=$RSYNC
    echo RSYNCOPTS=$RSYNCOPTS
    echo Modules:
    echo MODULES=$MODULES
    echo MODULEMAPPING=$MODULEMAPPING
    echo Misc:
    echo VERBOSE=$VERBOSE
fi

(( VERBOSE >= 8 )) && set -x

if [[ -n $MIRRORBUFFET ]]; then
    # We want to mirror everything, so save the admin from listing the
    # individual modules.
    # ZSHISM (get keys from an associative array with (k))
    MODULES=(${(k)MODULEMAPPING})
    # BASHEQ MODULES=${!MODULEMAPPING[@]}
    # bash3 equivalent is terrible
fi


# Master file list fetching
# =========================
sep
logit o Remote file list download start
db2 Downloading file lists
# ZSHISM (declare associative array)
typeset -A checksums
for module in $MODULES; do
    # ZSHISM? (associative array indexing)
    moduledir=$MODULEMAPPING[$module]
    mkdir $moduledir
    flname=${FILELIST/'$mdir'/$moduledir}
    if [[ -f $DESTD/$moduledir/$flname ]]; then
        cp -p $DESTD/$moduledir/$flname $moduledir
        # ZSHISM (assign assoc. array value)
        checksums[$module]=$(sha1sum $DESTD/$moduledir/$flname | cut -d' ' -f1)
    fi

    echo $moduledir/$flname >> filelist-transferlist
done

extra=(--no-dirs --relative --compress)
do_rsync $REMOTE/$MASTERMODULE/ . filelist-transferlist extra
rsyncreturn=$?
if [[ $rsyncreturn -ne 0 ]]; then
    (>&2 echo "rsync finished with nonzero exit status.\nCould not retrieve file lists.")
    logit E Aborting due to rsync failure while retrieving file lists
    finish
fi

# Log very basic stats
logit s "File list download: $(hr_b $rstotalbytesreceived) received, $(hr_b $rstransferspeed)/s"

# rsync won't transfer those files to the current directory, so move them and
# clean up.
mv */* .
rmdir * 2> /dev/null
logit o Remote file list download: end

# File list generation
# ====================
logit p Processing start
for module in $MODULES; do
    # ZSHISM? (associative array indexing)
    moduledir=$MODULEMAPPING[$module]

    fl=${FILELIST/'$mdir'/$moduledir}
    ffl=${FFILELIST/'$mdir'/$moduledir}
    totallines=0

    # First fetch each filefiletimelist, and make one big transfer list from
    # all of them.  Copy in the old file from our repo to speed up rsync in case
    # most of it didn't change
    if [[ -z $alwayscheck && \
            -n $checksums[$module] && \
            $(sha1sum $fl | cut -d' ' -f1) == $checksums[$module] ]]; then
        logit N No change in file list for $module
        db2 No change in file list checksum.  Skipping $module.
        continue
    fi

    sep
    logit P Processing start: $module
    db2 Processing $module

    flversion=$(awk -F '\t' '/^\[Version/ {s=1; next} /^$/ {exit} {if (s) print $0}' < $fl)
    if [[ "$flversion" -gt 3 ]]; then
        (>&2 echo File list version from the mirror cannot be processed by this script.
        echo Skipping $module.)
        continue
    fi

    tail -2 $fl | grep -q '^\[End\]$'
    if (( ? != 0 )); then
        (>&2 echo "No end marker.  Corrupted file list?"
        echo Skipping $module.)
        continue
    fi

    db3 Extracting file and directory lists.

    # All files in the remote repository.
    # Extract with the sizes and then extract just the file names from that.
    awk -F '\t' "/\\[Files/ {s=1;next} /^\$/ {s=0;next}
                 {if (s && \$2 == \"f\" || \$2 == \"l\")
                        print \"$moduledir/\" \$4 \"\t\" \$3}
                " $fl > allfilesizes-$module

    # Filter the list if requested.
    filter allfilesizes-$module

    # Produce the file list.
    awk -F '\t' '{print $1}' allfilesizes-$module > allfiles-$module

    # All dirs in the remote repository.
    # XXX This code is duplicated later, and should be pulled into a separate
    # function.
    awk -F '\t' "/\\[Files/ {s=1;next} /^\$/ {s=0;next}
                 { if (s && \$2 == \"d\")
                        print \"$moduledir/\" \$4}
                " < $fl > alldirs-$module

    # Filter the list if requested.
    filter alldirs-$module

    linecount=$(wc -l < allfiles-$module)
    linecount2=$(wc -l < alldirs-$module)
    db2f "Total on server:       %7d files, %4d dirs.\n" $linecount $linecount2

    # Files on the server which changed since the last run
    awk -F '\t' "/\\[Files/ {s=1;next} /^\$/ {s=0;next}
                 { if (s && \$1 >= $LASTTIME && (\$2 == \"f\" || \$2 == \"l\"))
                        print \"$moduledir/\" \$4}
                " < $fl > newfiles-$module

    # Filter the list if requested.
    filter newfiles-$module

    # Dirs on the server which changed since the last run
    awk -F '\t' "/\\[Files/ {s=1;next} /^\$/ {s=0;next}
                 { if (s && \$1 >= $LASTTIME &&(\$2 == \"d\"))
                        print \"$moduledir/\" \$4}
                " < $fl > newdirs-$module

    # Filter the list if requested.
    filter newdirs-$module

    linecount=$(wc -l < newfiles-$module)
    linecount2=$(wc -l < newdirs-$module)
    db2f "New on server:         %7d files, %4d dirs.\n" $linecount $linecount2

    echo $moduledir/$fl >> newfiles-$module
    echo $moduledir/$ffl >> newfiles-$module
    cat newfiles-$module >> transferlist-$module
    cat newdirs-$module >> transferlist-$module
    totallines=$((totallines+linecount+linecount2+1))

    if [[ -d $DESTD/$moduledir ]]; then
        db3 Generating local file/dir list
        logit l Generating file list start: $module

        # Traverse the filesystem only once
        pushd $DESTD
        find $moduledir/* -printf '%y\t%p\t%s\n' > $tempd/localfulllist-$module
        popd

        # Now extract file and dir lists from that
        awk -F '\t' '{if ($1 == "d") {print $2}}' < localfulllist-$module > localdirs-$module
        awk -F '\t' '{if ($1 == "f" || $1 == "l") {print $2}}' < localfulllist-$module > localfiles-$module
        awk -F '\t' '{if ($1 == "f" || $1 == "l") {print $2 "\t" $3}}' < localfulllist-$module > localfilesizes-$module

        # Look for stray .~tmp~ dirs
        if [[ -z $NORSYNCRECOVERY ]]; then
            grep '\.~tmp~' localdirs-$module > staletmpdirs-$module
            grep '\.~tmp~' localfiles-$module > staletmpfiles-$module
        fi

        if [[ -s staletmpdirs-$module ]]; then
            db2 Possibly aborted rsync run.  Cleaning up.
            logit a "cleaning up previous aborted run: $(wc -l < staletmpfiles-$module) file(s)."

            # Move the files in those tmpdirs a level up if a file with the
            # same name doesn't exist.  We don't update the file lists because
            # we want rsync to re-check those files and possibly fix up the
            # permissions.  The dirs will be cleaned up later.
            # Note that this _may_ leave a few files around which should not be
            # there.  They will of course be cleaned up at the next run.
            # XXX We could do better by comparing the stale files against the
            #   to-be-fransferred list, but it's probably not worth it.
            for dir in $(cat staletmpdirs-$module); do
                pushd $DESTD/$dir
                for file in *; do
                    if [[ ! -f ../$file ]]; then
                        logit A Saving previous download $file
                        db3 Saving previous download: $file
                        mv $file ..
                    fi
                done
                popd
            done
        logit l Generating file list end: $module
        fi

        # Find files on the client which don't exist on the server
        sort allfiles-$module allfiles-$module localfiles-$module \
            | uniq -u \
            | egrep -v '^[^/]*/fullfile(time)?list' > deletefiles-$module
        cat deletefiles-$module >> master-deletefiles

        # Find dirs on the client which don't exist on the server
        sort alldirs-$module alldirs-$module localdirs-$module \
            | uniq -u > deletedirs-$module
        cat deletedirs-$module >> master-deletedirs

        # Extract dirnames of every file and dir in the delete lists, and all of their parents.
        if [[ -n $updatealldirtimes ]]; then
            cat alldirs-$module >> master-updatetimestamps
        else
            awk '{dn($0)} function dn(p) { while (sub(/\/[^\/]*\]?$/, "", p)) print p }' \
                deletefiles-$module deletedirs-$module \
                | sort -u > updatetimestamps-$module
            cat updatetimestamps-$module >> master-updatetimestamps
        fi

        # Find files on the server which are missing on the client
        sort localfiles-$module localfiles-$module allfiles-$module \
            | uniq -u > missingfiles-$module
        cat missingfiles-$module >> transferlist-$module

        # Find dirs on the server which are missing on the client
        sort localdirs-$module localdirs-$module alldirs-$module \
            | uniq -u > missingdirs-$module
        cat missingdirs-$module >> transferlist-$module

        # Find files which have changed size
        sort allfilesizes-$module localfilesizes-$module \
            | uniq -u | awk -F '\t' '{print $1}' \
            | uniq -d > updatedfiles-$module
        cat updatedfiles-$module >> transferlist-$module

        # Extract and verify checksums
        awk -F '\t' "/^\[Checksums/ {s=1; next} /^$/ {s=0; next} {if (s) print \$1 \"\\t$moduledir/\" \$2}" $fl > checksums-$module
        pushd $DESTD > /dev/null 2>&1
        sha1sum --check --quiet $tempd/checksums-$module 2> /dev/null \
            | grep -i 'failed$' \
            | awk -F: '{print $1}' > $tempd/checksumfailed-$module
        popd > /dev/null 2>&1
        cat checksumfailed-$module >> transferlist-$module

        # Count some things we want to use for stats later.
        cntlocalfiles=$(wc -l < localfiles-$module)
        cntlocaldirs=$(wc -l < localdirs-$module)

        cntextrafiles=$(wc -l < deletefiles-$module)
        cntextradirs=$(wc -l < deletedirs-$module)

        cntmissingfiles=$(wc -l < missingfiles-$module)
        cntmissingdirs=$(wc -l < missingdirs-$module)
        totallines=$((totallines+cntmissingfiles+cntmissingdirs))

        cntsizechanged=$(wc -l < updatedfiles-$module)
        totallines=$((totallines+cntsizechanged))

        cntupdatetimestamps=$(wc -l < updatetimestamps-$module)

        cntchecksumfailed=$(wc -l < checksumfailed-$module)
        totallines=$((totallines+cntchecksumfailed))

        db2f "Total on client:       %7d files, %4d dirs.\n" $cntlocalfiles $cntlocaldirs
        db2f "Not present on server: %7d files, %4d dirs.\n" $cntextrafiles $cntextradirs
        db2f "Missing on client:     %7d files, %4d dirs.\n" $cntmissingfiles $cntmissingdirs
        db2f "Size Changed:          %7d files.\n" $cntsizechanged
        db2f "Timestamps to restore: %7d files.\n" $cntupdatetimestamps
        db2f "Checksum Failed:       %7d files.\n" $cntchecksumfailed
    fi

    sort -u transferlist-$module >> transferlist-sorted-$module
    cat transferlist-sorted-$module >> master-transferlist
    cnttotaltransfer=$(wc -l < transferlist-sorted-$module)

    logit P Processing end: $module
    db2 Finished processing $module.
    db2 After removing duplicates, $cnttotaltransfer files and dirs were added to the transfer list.

    # Clean up a bit.
    # XXX We need at least the dirlists for the checkin
    #if (( VERBOSE <= 4 )); then
    #    rm *-$module
    #fi
done

if [[ ! -e master-transferlist ]]; then
    logit n No changes to synchronize
    db2 No changed files.
    finish no
fi

if [[ -n $MIRRORBUFFET ]]; then
    echo DIRECTORY_SIZES.txt >> master-transferlist
fi

# The actual transfer
# ===================
sort -u master-transferlist > master-transferlist.sorted
linecount=$(wc -l < master-transferlist.sorted)
sep; sep
db2 Transferring $linecount files.

# Now we have a list of everything which has changed recently in every module
# we want, pass that to rsync (non recursive mode!) and it should transfer just
# the changed files without having to pull the entire huge file list.
extra=()
if [[ -n $rsyncdryrun ]]; then
    extra+=(-n)
fi
do_rsync $REMOTE/$MASTERMODULE/ $DESTD master-transferlist.sorted extra
rsyncreturn=$?
if [[ $rsyncreturn -ne 0 ]]; then
    (>&2 echo "rsync finished with nonzero exit status.\nWill not check in or delete anything.")
    logit E skipping further operations due to rsync failure
    finish
fi

# Total downloaded file count, bytes received, transfer speed
logit s "stat: downloaded $rsfilestransferred files"
logit s "stat: received $(hr_b $rstotalbytesreceived)"
logit s "stat: transfer speed $(hr_b $rstransferspeed)/s"

# Everything we can extract from rsync
logit S "stat: sent $(hr_b $rstotalbytessent)"
logit S "stat: speedup: $rsspeedup"
logit S "stat: total size of transferred files: $(hr_b $rsfilesize)"
logit S "stat: file list gen time $(hr_s $rsfilelistgentime)"
logit S "stat: file list transfer time $(hr_s $rsfilelisttransfertime)"

db1 "========================="
db1 "Main transfer statistics:"
db1 "    Downloaded files: $rsfilestransferred"
db1 "    Total size of those files: $(hr_b $rsfilesize)"
db1 "    Received: $(hr_b $rstotalbytesreceived)"
db1 "    Sent: $(hr_b $rstotalbytessent)"
db1 "    Speedup: $rsspeedup"
db1 "    Trasfer speed: $(hr_b $rstransferspeed)/s"
db1 "    File list generation time: $(hr_s $rsfilelistgentime)"
db1 "    File list transfer time: $(hr_s $rsfilelisttransfertime)"

# Local dir/file deletion
# =======================
if [[ -s master-deletedirs ]]; then
    linecount=$(wc -l < master-deletedirs)

    if [[ -n $skipdelete && $VERBOSE -ge 2 ]]; then
        logit d Directory deletion skipped
        echo Not deleting  $linecount directories.  Delete list is:
        cat master-deletedirs
        echo
    else
        logit d Directory deletion start: $linecount directories
        db2 Removing $linecount stale directories.
        for nuke in $(cat master-deletedirs); do
            if [[ -d "$DESTD/$nuke" ]]; then
                logit D Deleting directory $nuke
                db4 Removing $nuke
                rm -rf "$DESTD/$nuke"
                deletedsomething=1
            fi
        done
        logit d Directory deletion end
    fi
else
    db2 No stale directories to delete.
fi

if [[ -s master-deletefiles ]]; then
    linecount=$(wc -l < master-deletefiles)

    if [[ -n $skipdelete ]]; then
        logit d File deletion skipped
        echo Not deleting $linecount stale files.  Delete list is:
        cat master-deletefiles
        echo
    else
        logit d File deletion begin: $linecount files
        db2 Removing $linecount stale files.
        # xopts=()
        # (( VERBOSE >= 4 )) && xopts=(-t)
        tr '\n' '\0' < master-deletefiles \
            | (pushd $DESTD; xargs $xopts -0 rm -f ; popd)
        # for nuke in $(cat master-deletefiles); do
        #     logit D Deleting file $nuke
        #     rm -f "$DESTD/$nuke"
        # done
        deletedsomething=1
        logit d File deletion end
    fi
else
    db2 No stale files to delete.
fi

if [[ -n $KEEPDIRTIMES && -s master-updatetimestamps ]]; then
    extra=()
    if [[ -n $rsyncdryrun ]]; then
        extra+=(-n)
    fi
    logit d "Updating timestamps on $(wc -l < master-updatetimestamps) dirs"
    do_rsync $REMOTE/$MASTERMODULE/ $DESTD master-updatetimestamps extra
fi

# State saving
# ============
if [[ -z $skiptimestamp ]]; then
    db2 Saving mirror time to $TIMEFILE
    if [[ -e $TIMEFILE ]]; then
        mv $TIMEFILE $TIMEFILE.prev
    fi
    echo LASTTIME=$starttime > $TIMEFILE

    if (( ? != 0 )); then
        (>&2 echo Problem saving timestamp file $TIMEFILE)
        exit 1
    fi
else
    db2 Skipping timestamp save.
    finish
fi

# Mirrormanager Checkin and Callout
# =================================
# At this point we know that we had a clean run with no complaints from rsync,
# and as far as we're concerned the run is now complete and recorded.
#
# So for each module we mirrored, the filtered file list is correct.  This
# means that the alldirs-$module file is accurate and we can simply report its
# contents to mirrormanager.
if [[ -z $CHECKIN_SITE || -n $skipcheckin ]]; then
    finish
fi

db2 Performing mirrormanager checkin
logit m "mirrormanager checkin start"
mm=mirrormanager-payload
mx=mirrormanager-xmlrpc

# First construct the checkin payload

# The json produced by report_mirror will start with a bracket, followed by
# info for each module, followed by some data relating to the host and site
# being reported.
echo '{' > $mm

for module in $MODULES; do
    moduledir=$MODULEMAPPING[$module]
    mmcheckin=$MIRRORMANAGERMAPPING[$module]

    logit M "Processing $module, $moduledir"

    # mirrormanager expects a list of everything we have.  We might not have
    # seen any changes in the file list and so wouldn't have generated this
    # file earlier.
    # XXX This code is duplicated from above, and should be pulled out to a
    # separate function.
    if [[ ! -f alldirs-$module ]]; then
        logit M "Generating dirlist for $module"
        fl=${FILELIST/'$mdir'/$moduledir}
        awk -F '\t' "/\\[Files/ {s=1;next} /^\$/ {s=0;next}
            { if (s && \$2 == \"d\")
                print \"$moduledir/\" \$4}
                " < $fl > alldirs-$module

        # Filter the list if requested.
        filter alldirs-$module
    fi

    # The beginning of the json bit
    cat >>$mm <<EOF
    "$mmcheckin": {
        "dirtree": {
EOF

    # Output the data for each directory.  MM doesn't want the
    # directory name.
    for l in $(cat alldirs-$module); do
        cat >>$mm <<EOF
            "${l/$moduledir\/}": {},
EOF
    done

    # The data sent by report_mirror always includes a blank directory; add it
    # manually here which conveniently means we don't have to deal with the
    # trailing comma.
    cat >>$mm <<EOF
            "": {}
        },
        "enabled": "1"
    },
EOF
done

cat >>$mm <<EOF
    "global": {
        "enabled": "1",
        "server": "$MIRRORMANAGER"
    },
    "host": {
        "enabled": "1",
        "name": "$CHECKIN_HOST"
    },
    "site": {
        "enabled": "1",
        "name": "$CHECKIN_SITE",
        "password": "$CHECKIN_PASSWORD"
    },
    "stats": {},
    "version": 0
}
EOF

# The xmlrpc endpoint requires that the payload be bzip2 compressed
bzip2 $mm

# base64 encode
base64 --wrap=0 $mm.bz2 > $mm.bz2.b64

# change '+' to '-'  and '/' to '_'
tr '+/' '-_' < $mm.bz2.b64 > $mm.bz2.b64.tr

# Wrap the transformed, base64 encoded bzip2 compressed json payload in just
# the right xml
# XXX I hope that newlines are allowed inside the <string> block.
cat >>$mx <<EOF
<?xml version='1.0'?>
<methodCall>
<methodName>checkin</methodName>
<params>
<param>
EOF
echo -n "<value><string>" >>$mx

cat <$mm.bz2.b64.tr >>$mx

cat >>$mx <<EOF
</string></value>
</param>
</params>
</methodCall>
EOF

# Now actually upload the payload
# We have to remove the Expect: header that curl sends but which mirrormanager cannot handle
logit M "Making xmlrpc call"
curlopts=(--silent)
(( VERBOSE >= 4 )) && curlopts=(--verbose)
$CURL $curlopts -H "Expect:" -H "Content-Type: text/xml" --data @$mx $MIRRORMANAGER > curl.out
curlret=$?
if [[ $curlret -ne 0 ]]; then
    logit E "Checkin failure: curl returned $curlret"
    (>&2 echo "Checkin failure: curl returned $curlret")
    finish
fi

# Parse the output to see if we got any useful return
# The sed call attempts to strip xml tags.  Easily fooled but we don't expect
# any complicated return from mirrormanager.
sed -e 's/<[^>]*>//g' curl.out > curl.noxml
grep -q -i successful curl.noxml

if [[ $? -ne 0 ]]; then
    logit E "Doesn't look like we got a good return from mirrormanager."
    logit E $(cat curl.noxml)
fi

logit m "mirrormanager checkin end"
finish
